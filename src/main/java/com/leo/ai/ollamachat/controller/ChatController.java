package com.leo.ai.ollamachat.controller;

import com.leo.ai.ollamachat.dto.ChatRequest;
import com.leo.ai.ollamachat.dto.ChatResponse;
import com.leo.ai.ollamachat.model.ChatMessage;
import com.leo.ai.ollamachat.repository.ChatMessageRepository;
import com.leo.ai.ollamachat.service.OllamaService;
import org.springframework.http.MediaType;
import org.springframework.web.bind.annotation.*;
import reactor.core.publisher.Flux;
import reactor.core.publisher.Mono;
import java.time.LocalDateTime;
import java.util.Map;

@RestController
@RequestMapping("/api/chat")
@CrossOrigin(origins = "*")
public class ChatController {

    private final OllamaService ollamaService;
    private final ChatMessageRepository chatRepository;

    public ChatController(OllamaService ollamaService, ChatMessageRepository chatRepository) {
        this.ollamaService = ollamaService;
        this.chatRepository = chatRepository;
    }

    /**
     * üîπ Endpoint de diagn√≥stico para o frontend
     */
    @GetMapping("/ping")
    public Map<String, String> ping() {
        return Map.of(
                "status", "OK",
                "message", "Backend est√° ativo e recebendo requisi√ß√µes!"
        );
    }

    /**
     * üß™ Endpoint de teste ‚Äî seu endpoint atual
     */
    @GetMapping("/test")
    public Map<String, String> test() {
        return Map.of("message", "‚úÖ Backend est√° respondendo corretamente.");
    }

    /**
     * ü§ñ Endpoint tradicional ‚Äî resposta completa (sem streaming).
     */
    @PostMapping
    public Mono<ChatResponse> chat(@RequestBody ChatRequest request) {
        String userMessage = request.getMessage();

        if (userMessage == null || userMessage.isBlank()) {
            return Mono.just(new ChatResponse("‚ö†Ô∏è A mensagem n√£o pode estar vazia."));
        }

        return ollamaService.askOllama(userMessage)
                .flatMap(responseMap -> {
                    String botResponse = extrairResposta(responseMap);

                    ChatMessage chatMessage = new ChatMessage();
                    chatMessage.setUserMessage(userMessage);
                    chatMessage.setBotResponse(botResponse);
                    chatMessage.setTimestamp(LocalDateTime.now());

                    return chatRepository.save(chatMessage)
                            .thenReturn(new ChatResponse(botResponse));
                })
                .onErrorResume(e -> Mono.just(new ChatResponse("‚ùå Erro: " + e.getMessage())));
    }

    /**
     * üì° Endpoint streaming ‚Äî resposta token a token.
     */
    @PostMapping(value = "/stream", produces = MediaType.TEXT_EVENT_STREAM_VALUE)
    public Flux<String> streamChat(@RequestBody ChatRequest request) {
        String prompt = request.getMessage();
        return ollamaService.streamOllamaResponse(prompt)
                .onErrorResume(e -> Flux.just("‚ùå Erro no streaming: " + e.getMessage()));
    }

    /**
     * üîç Extrai texto retornado pelo Ollama.
     */
    private String extrairResposta(Map<String, Object> responseMap) {
        if (responseMap == null) return "‚ö†Ô∏è Resposta vazia do Ollama.";

        Object raw = responseMap.get("response");
        if (raw == null) raw = responseMap.get("message");
        if (raw == null) raw = responseMap.get("output");
        if (raw == null) raw = responseMap.get("content");

        return raw != null ? raw.toString() : "‚ö†Ô∏è Erro ao processar resposta do modelo.";
    }
}
